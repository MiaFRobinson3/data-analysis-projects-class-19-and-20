{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894ccac",
   "metadata": {},
   "source": [
    "# Data Manipulation Studio\n",
    "\n",
    "For this studio, we will revisit the data set from our last studio. If you recall, California farmers were looking for advice on growing pumpkins. We will use the same [pumpkins dataset](https://www.kaggle.com/usda/a-year-of-pumpkin-prices) as provided by the U.S. Department of Agriculture. You may have to clean data in the process of data manipulation, so feel free to pull up your notebook from the last class's studio.\n",
    "\n",
    "We will now be focusing our attention on a different region in the United States, the Northeast. When you open up the `dataset` folder, you will have 13 CSVs, including the San Francisco and Los Angeles data from the last lesson. The 13 CSVs are each a different terminal market in the United States.\n",
    "\n",
    "A **terminal market** is a central site, often in a metropolitan area, that serves as an assembly and trading place for commodities. Terminal markets for agricultural commodities are usually at or near major transportation hubs. [Definition Source](https://en.wikipedia.org/wiki/Terminal_market#:~:text=A%20terminal%20market%20is%20a,or%20near%20major%20transportation%20hubs)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Import the CSVs for each of the following cities: Baltimore, Boston, New York, and Philadelphia. Set up a dataframe for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c9a7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baltimore Data\n",
      "  Commodity Name  City Name  Type       Package      Variety Sub Variety  \\\n",
      "0       PUMPKINS  BALTIMORE   NaN  24 inch bins          NaN         NaN   \n",
      "1       PUMPKINS  BALTIMORE   NaN  24 inch bins          NaN         NaN   \n",
      "2       PUMPKINS  BALTIMORE   NaN  24 inch bins  HOWDEN TYPE         NaN   \n",
      "3       PUMPKINS  BALTIMORE   NaN  24 inch bins  HOWDEN TYPE         NaN   \n",
      "4       PUMPKINS  BALTIMORE   NaN  24 inch bins  HOWDEN TYPE         NaN   \n",
      "5       PUMPKINS  BALTIMORE   NaN  24 inch bins  HOWDEN TYPE         NaN   \n",
      "6       PUMPKINS  BALTIMORE   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "7       PUMPKINS  BALTIMORE   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "8       PUMPKINS  BALTIMORE   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "9       PUMPKINS  BALTIMORE   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "\n",
      "   Grade        Date  Low Price  High Price  ...  Color  Environment  \\\n",
      "0    NaN  04/29/2017        270       280.0  ...    NaN          NaN   \n",
      "1    NaN  05/06/2017        270       280.0  ...    NaN          NaN   \n",
      "2    NaN  09/24/2016        160       160.0  ...    NaN          NaN   \n",
      "3    NaN  09/24/2016        160       160.0  ...    NaN          NaN   \n",
      "4    NaN  11/05/2016         90       100.0  ...    NaN          NaN   \n",
      "5    NaN  11/12/2016         90       100.0  ...    NaN          NaN   \n",
      "6    NaN  09/24/2016        160       170.0  ...    NaN          NaN   \n",
      "7    NaN  09/24/2016        160       160.0  ...    NaN          NaN   \n",
      "8    NaN  10/01/2016        160       170.0  ...    NaN          NaN   \n",
      "9    NaN  10/01/2016        160       160.0  ...    NaN          NaN   \n",
      "\n",
      "  Unit of Sale  Quality Condition Appearance  Storage Crop  Repack  Trans Mode  \n",
      "0          NaN      NaN       NaN        NaN      NaN  NaN       E         NaN  \n",
      "1          NaN      NaN       NaN        NaN      NaN  NaN       E         NaN  \n",
      "2          NaN      NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "3          NaN      NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "4          NaN      NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "5          NaN      NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "6          NaN      NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "7          NaN      NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "8          NaN      NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "9          NaN      NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "\n",
      "[10 rows x 25 columns]\n",
      "Boston Data\n",
      "  Commodity Name City Name  Type       Package      Variety Sub Variety  \\\n",
      "0       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "1       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "2       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "3       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "4       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "5       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "6       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "7       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "8       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "9       PUMPKINS    BOSTON   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "\n",
      "   Grade        Date  Low Price  High Price  ...   Color  Environment  \\\n",
      "0    NaN  09/24/2016        160         200  ...  ORANGE          NaN   \n",
      "1    NaN  09/24/2016        160         200  ...  ORANGE          NaN   \n",
      "2    NaN  09/24/2016        160         200  ...  ORANGE          NaN   \n",
      "3    NaN  09/24/2016        160         200  ...  ORANGE          NaN   \n",
      "4    NaN  09/24/2016        160         180  ...  ORANGE          NaN   \n",
      "5    NaN  09/24/2016        160         180  ...  ORANGE          NaN   \n",
      "6    NaN  09/24/2016        140         160  ...  ORANGE          NaN   \n",
      "7    NaN  09/24/2016        140         160  ...  ORANGE          NaN   \n",
      "8    NaN  09/24/2016        140         160  ...  ORANGE          NaN   \n",
      "9    NaN  09/24/2016        200         225  ...  ORANGE          NaN   \n",
      "\n",
      "  Unit of Sale Quality Condition Appearance  Storage Crop  Repack  Trans Mode  \n",
      "0          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "1          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "2          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "3          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "4          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "5          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "6          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "7          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "8          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "9          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "\n",
      "[10 rows x 25 columns]\n",
      "New York Data\n",
      "  Commodity Name City Name  Type       Package      Variety Sub Variety  \\\n",
      "0       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "1       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "2       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "3       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "4       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "5       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "6       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "7       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "8       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "9       PUMPKINS  NEW YORK   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "\n",
      "   Grade        Date  Low Price  High Price  ...  Color  Environment  \\\n",
      "0    NaN  09/24/2016        150         170  ...    NaN          NaN   \n",
      "1    NaN  09/24/2016        150         170  ...    NaN          NaN   \n",
      "2    NaN  09/24/2016        130         150  ...    NaN          NaN   \n",
      "3    NaN  09/24/2016        130         150  ...    NaN          NaN   \n",
      "4    NaN  09/24/2016        120         140  ...    NaN          NaN   \n",
      "5    NaN  09/24/2016        150         170  ...    NaN          NaN   \n",
      "6    NaN  09/24/2016        120         170  ...    NaN          NaN   \n",
      "7    NaN  09/24/2016        180         190  ...    NaN          NaN   \n",
      "8    NaN  10/01/2016        150         170  ...    NaN          NaN   \n",
      "9    NaN  10/01/2016        150         170  ...    NaN          NaN   \n",
      "\n",
      "  Unit of Sale Quality Condition Appearance  Storage Crop  Repack  Trans Mode  \n",
      "0          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "1          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "2          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "3          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "4          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "5          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "6          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "7          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "8          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "9          NaN     NaN       NaN        NaN      NaN  NaN       N         NaN  \n",
      "\n",
      "[10 rows x 25 columns]\n",
      "Philadelphia Data\n",
      "  Commodity Name     City Name  Type       Package      Variety Sub Variety  \\\n",
      "0       PUMPKINS  PHILADELPHIA   NaN  24 inch bins  HOWDEN TYPE         NaN   \n",
      "1       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "2       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "3       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "4       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "5       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "6       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "7       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "8       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "9       PUMPKINS  PHILADELPHIA   NaN  36 inch bins  HOWDEN TYPE         NaN   \n",
      "\n",
      "   Grade        Date  Low Price  High Price  ...  Color  Environment  \\\n",
      "0    NaN  09/16/2017        140         150  ...    NaN          NaN   \n",
      "1    NaN  09/24/2016        150         150  ...    NaN          NaN   \n",
      "2    NaN  09/24/2016        150         150  ...    NaN          NaN   \n",
      "3    NaN  09/24/2016        150         160  ...    NaN          NaN   \n",
      "4    NaN  10/01/2016        140         140  ...    NaN          NaN   \n",
      "5    NaN  10/01/2016        140         140  ...    NaN          NaN   \n",
      "6    NaN  10/01/2016        120         120  ...    NaN          NaN   \n",
      "7    NaN  10/08/2016        140         155  ...    NaN          NaN   \n",
      "8    NaN  10/08/2016        120         120  ...    NaN          NaN   \n",
      "9    NaN  10/15/2016        120         125  ...    NaN          NaN   \n",
      "\n",
      "  Unit of Sale  Quality Condition  Appearance  Storage Crop  Repack  \\\n",
      "0          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "1          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "2          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "3          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "4          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "5          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "6          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "7          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "8          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "9          NaN      NaN       NaN         NaN      NaN  NaN       N   \n",
      "\n",
      "   Trans Mode  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "5         NaN  \n",
      "6         NaN  \n",
      "7         NaN  \n",
      "8         NaN  \n",
      "9         NaN  \n",
      "\n",
      "[10 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries and CSVs. Make some dataframes!\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df_Baltimore = pd.read_csv(\"/Users/miafusco/Documents/LaunchCode/data-analysis-projects2/data-analysis-projects-class-19-and-20/class-18/studio/dataset/baltimore_9-24-2016_9-30-2017.csv\")\n",
    "df_Boston = pd.read_csv(\"/Users/miafusco/Documents/LaunchCode/data-analysis-projects2/data-analysis-projects-class-19-and-20/class-18/studio/dataset/boston_9-24-2016_9-30-2017.csv\")\n",
    "df_New_York = pd.read_csv(\"/Users/miafusco/Documents/LaunchCode/data-analysis-projects2/data-analysis-projects-class-19-and-20/class-18/studio/dataset/new-york_9-24-2016_9-30-2017.csv\")\n",
    "df_Philadelphia = pd.read_csv(\"/Users/miafusco/Documents/LaunchCode/data-analysis-projects2/data-analysis-projects-class-19-and-20/class-18/studio/dataset/philadelphia_9-24-2016_9-30-2017.csv\")\n",
    "\n",
    "print(\"Baltimore Data\")\n",
    "print(df_Baltimore.head(10))\n",
    "\n",
    "print(\"Boston Data\")\n",
    "print(df_Boston.head(10))\n",
    "\n",
    "print(\"New York Data\")\n",
    "print(df_New_York.head(10))\n",
    "\n",
    "print(\"Philadelphia Data\")\n",
    "print(df_Philadelphia.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2ec94e5-9350-48bd-afa3-a0d259d8c4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baltimore Columna\n",
      "Index(['Commodity Name', 'City Name', 'Type', 'Package', 'Variety',\n",
      "       'Sub Variety', 'Grade', 'Date', 'Low Price', 'High Price', 'Mostly Low',\n",
      "       'Mostly High', 'Origin', 'Origin District', 'Item Size', 'Color',\n",
      "       'Environment', 'Unit of Sale', 'Quality', 'Condition', 'Appearance',\n",
      "       'Storage', 'Crop', 'Repack', 'Trans Mode'],\n",
      "      dtype='object')\n",
      "Boston Columns\n",
      "Index(['Commodity Name', 'City Name', 'Type', 'Package', 'Variety',\n",
      "       'Sub Variety', 'Grade', 'Date', 'Low Price', 'High Price', 'Mostly Low',\n",
      "       'Mostly High', 'Origin', 'Origin District', 'Item Size', 'Color',\n",
      "       'Environment', 'Unit of Sale', 'Quality', 'Condition', 'Appearance',\n",
      "       'Storage', 'Crop', 'Repack', 'Trans Mode'],\n",
      "      dtype='object')\n",
      "New York Columns\n",
      "Index(['Commodity Name', 'City Name', 'Type', 'Package', 'Variety',\n",
      "       'Sub Variety', 'Grade', 'Date', 'Low Price', 'High Price', 'Mostly Low',\n",
      "       'Mostly High', 'Origin', 'Origin District', 'Item Size', 'Color',\n",
      "       'Environment', 'Unit of Sale', 'Quality', 'Condition', 'Appearance',\n",
      "       'Storage', 'Crop', 'Repack', 'Trans Mode'],\n",
      "      dtype='object')\n",
      "Philadelphia Columns\n",
      "Index(['Commodity Name', 'City Name', 'Type', 'Package', 'Variety',\n",
      "       'Sub Variety', 'Grade', 'Date', 'Low Price', 'High Price', 'Mostly Low',\n",
      "       'Mostly High', 'Origin', 'Origin District', 'Item Size', 'Color',\n",
      "       'Environment', 'Unit of Sale', 'Quality', 'Condition', 'Appearance',\n",
      "       'Storage', 'Crop', 'Repack', 'Trans Mode'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Baltimore Columna\")\n",
    "print(df_Baltimore.columns)\n",
    "\n",
    "print(\"Boston Columns\")\n",
    "print(df_Boston.columns)\n",
    "\n",
    "print(\"New York Columns\")\n",
    "print(df_New_York.columns)\n",
    "\n",
    "print(\"Philadelphia Columns\")\n",
    "print(df_Philadelphia.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda42f",
   "metadata": {},
   "source": [
    "## Clean Your Data\n",
    "\n",
    "In the last lesson, we cleaned the data related to San Francisco. Pull up your notebook from the last lesson and use it as a reference to clean up these new dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98abc290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data Baltimore\n",
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 1%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 3%\n",
      "Origin District - 100%\n",
      "Item Size - 16%\n",
      "Color - 80%\n",
      "Environment - 100%\n",
      "Unit of Sale - 84%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n",
      "Missing Data Boston\n",
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 92%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 81%\n",
      "Item Size - 1%\n",
      "Color - 14%\n",
      "Environment - 100%\n",
      "Unit of Sale - 87%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n",
      "Missing Data New York\n",
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 87%\n",
      "Item Size - 7%\n",
      "Color - 81%\n",
      "Environment - 100%\n",
      "Unit of Sale - 78%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n",
      "Missing Data Philadelphia\n",
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 79%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 100%\n",
      "Item Size - 21%\n",
      "Color - 100%\n",
      "Environment - 100%\n",
      "Unit of Sale - 81%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "# Clean your data here!\n",
    "print(\"Missing Data Baltimore\")\n",
    "for col in df_Baltimore.columns:\n",
    "    pct_missing = np.mean(df_Baltimore[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "print(\"Missing Data Boston\")\n",
    "for col in df_Boston.columns:\n",
    "    pct_missing = np.mean(df_Boston[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "print(\"Missing Data New York\")\n",
    "for col in df_New_York.columns:\n",
    "    pct_missing = np.mean(df_New_York[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "print(\"Missing Data Philadelphia\")\n",
    "for col in df_Philadelphia.columns:\n",
    "    pct_missing = np.mean(df_Philadelphia[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9793279-25bf-442d-bd08-dd2ee24b7c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Baltimore['Color'].unique()\n",
    "df_Boston['Color'].unique()\n",
    "df_New_York['Color'].unique()\n",
    "df_Philadelphia['Color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "657ac8c6-40ed-4d1e-87f7-c0e7b51aba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baltimore Value Counts\n",
      "Color\n",
      "ORANGE    17\n",
      "WHITE     14\n",
      "Name: count, dtype: int64\n",
      "Boston Value Counts\n",
      "Color\n",
      "ORANGE    276\n",
      "WHITE      28\n",
      "Name: count, dtype: int64\n",
      "New York Value Counts\n",
      "Color\n",
      "ORANGE    11\n",
      "WHITE     10\n",
      "Name: count, dtype: int64\n",
      "Philadelphia Value Counts\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Baltimore Value Counts\")\n",
    "print(df_Baltimore['Color'].value_counts())\n",
    "\n",
    "print(\"Boston Value Counts\")\n",
    "print(df_Boston['Color'].value_counts())\n",
    "\n",
    "print(\"New York Value Counts\")\n",
    "print(df_New_York['Color'].value_counts())\n",
    "\n",
    "print(\"Philadelphia Value Counts\")\n",
    "print(df_Philadelphia['Color'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b01b9",
   "metadata": {},
   "source": [
    "## Combine Your Data\n",
    "\n",
    "Now that you have four clean sets of data, combine all four into one dataframe that represents the entire Northeast region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da059f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Commodity Name     City Name  Type             Package      Variety  \\\n",
      "0        PUMPKINS     BALTIMORE   NaN        24 inch bins          NaN   \n",
      "1        PUMPKINS     BALTIMORE   NaN        24 inch bins          NaN   \n",
      "2        PUMPKINS     BALTIMORE   NaN        24 inch bins  HOWDEN TYPE   \n",
      "3        PUMPKINS     BALTIMORE   NaN        24 inch bins  HOWDEN TYPE   \n",
      "4        PUMPKINS     BALTIMORE   NaN        24 inch bins  HOWDEN TYPE   \n",
      "..            ...           ...   ...                 ...          ...   \n",
      "52       PUMPKINS  PHILADELPHIA   NaN  1/2 bushel cartons    MINIATURE   \n",
      "53       PUMPKINS  PHILADELPHIA   NaN  1/2 bushel cartons    MINIATURE   \n",
      "54       PUMPKINS  PHILADELPHIA   NaN  1/2 bushel cartons    MINIATURE   \n",
      "55       PUMPKINS  PHILADELPHIA   NaN  1/2 bushel cartons    MINIATURE   \n",
      "56       PUMPKINS  PHILADELPHIA   NaN  1/2 bushel cartons    MINIATURE   \n",
      "\n",
      "   Sub Variety  Grade        Date  Low Price  High Price  ...  Color  \\\n",
      "0          NaN    NaN  04/29/2017        270       280.0  ...    NaN   \n",
      "1          NaN    NaN  05/06/2017        270       280.0  ...    NaN   \n",
      "2          NaN    NaN  09/24/2016        160       160.0  ...    NaN   \n",
      "3          NaN    NaN  09/24/2016        160       160.0  ...    NaN   \n",
      "4          NaN    NaN  11/05/2016         90       100.0  ...    NaN   \n",
      "..         ...    ...         ...        ...         ...  ...    ...   \n",
      "52   FLAT TYPE    NaN  11/05/2016         16        18.0  ...    NaN   \n",
      "53   FLAT TYPE    NaN  08/26/2017         18        20.0  ...    NaN   \n",
      "54   FLAT TYPE    NaN  09/16/2017         16        16.0  ...    NaN   \n",
      "55   FLAT TYPE    NaN  09/23/2017         15        16.0  ...    NaN   \n",
      "56   FLAT TYPE    NaN  09/30/2017         15        18.0  ...    NaN   \n",
      "\n",
      "    Environment Unit of Sale Quality Condition Appearance  Storage Crop  \\\n",
      "0           NaN          NaN     NaN       NaN        NaN      NaN  NaN   \n",
      "1           NaN          NaN     NaN       NaN        NaN      NaN  NaN   \n",
      "2           NaN          NaN     NaN       NaN        NaN      NaN  NaN   \n",
      "3           NaN          NaN     NaN       NaN        NaN      NaN  NaN   \n",
      "4           NaN          NaN     NaN       NaN        NaN      NaN  NaN   \n",
      "..          ...          ...     ...       ...        ...      ...  ...   \n",
      "52          NaN   SHELLACKED     NaN       NaN        NaN      NaN  NaN   \n",
      "53          NaN   SHELLACKED     NaN       NaN        NaN      NaN  NaN   \n",
      "54          NaN   SHELLACKED     NaN       NaN        NaN      NaN  NaN   \n",
      "55          NaN   SHELLACKED     NaN       NaN        NaN      NaN  NaN   \n",
      "56          NaN   SHELLACKED     NaN       NaN        NaN      NaN  NaN   \n",
      "\n",
      "    Repack  Trans Mode  \n",
      "0        E         NaN  \n",
      "1        E         NaN  \n",
      "2        N         NaN  \n",
      "3        N         NaN  \n",
      "4        N         NaN  \n",
      "..     ...         ...  \n",
      "52       N         NaN  \n",
      "53       N         NaN  \n",
      "54       N         NaN  \n",
      "55       N         NaN  \n",
      "56       N         NaN  \n",
      "\n",
      "[674 rows x 25 columns]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m df_Northeast \u001b[38;5;241m=\u001b[39m df_Northeast\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      7\u001b[0m df_Northeast\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_Northeast\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCity Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[0;32m~/Documents/LaunchCode/data-analysis-projects2/virtual/lib/python3.12/site-packages/pandas/core/indexes/base.py:5416\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5407\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   5408\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   5409\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a boolean indexer with length 0 on an Index with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5410\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength greater than 0 is deprecated and will raise in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5413\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   5414\u001b[0m             )\n\u001b[0;32m-> 5416\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5417\u001b[0m \u001b[38;5;66;03m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[1;32m   5418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Combine the four dataframes into one!\n",
    "df_Northeast = pd.concat([df_Baltimore, df_Boston, df_New_York, df_Philadelphia], axis = 0)\n",
    "print(df_Northeast)\n",
    "\n",
    "df_Northeast.columns\n",
    "df_Northeast = df_Northeast.columns.str.strip()\n",
    "df_Northeast.dropna()\n",
    "\n",
    "print(df_Northeast['City Name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590082f",
   "metadata": {},
   "source": [
    "## Answer Some Questions\n",
    "\n",
    "Use `groupby()` and `agg()` to answer the following two questions:\n",
    "\n",
    "1. What is the mean low and high prices for each type of **unit of sale** in the Northeast region? \n",
    "2. For each region, what is the average number of pumpkins per variety that came into terminal markets for the year? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c839639a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Categorical input must be list-like",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Put your code here to find the mean low and high prices in the Northeast region for each type of unit of sale.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m unit_of_sale \u001b[38;5;241m=\u001b[39m \u001b[43mdf_Northeast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCity Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow Price\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh Price\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(unit_of_sale)\n",
      "File \u001b[0;32m~/Documents/LaunchCode/data-analysis-projects2/virtual/lib/python3.12/site-packages/pandas/core/indexes/base.py:6446\u001b[0m, in \u001b[0;36mIndex.groupby\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   6444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ABCMultiIndex):\n\u001b[1;32m   6445\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 6446\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6447\u001b[0m result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39m_reverse_indexer()\n\u001b[1;32m   6449\u001b[0m \u001b[38;5;66;03m# map to the label\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/LaunchCode/data-analysis-projects2/virtual/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:406\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(values):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# GH#38433\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategorical input must be list-like\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# null_mask indicates missing values we want to exclude from inference.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# This means: only missing values in list-likes (not arrays/ndframes).\u001b[39;00m\n\u001b[1;32m    410\u001b[0m null_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Categorical input must be list-like"
     ]
    }
   ],
   "source": [
    "# Put your code here to find the mean low and high prices in the Northeast region for each type of unit of sale.\n",
    "unit_of_sale = df_Northeast.groupby('City Name')[['Low Price','High Price']].mean()\n",
    "print(unit_of_sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4b23352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here to find the average number of pumpkins coming into terminal markets of each variety.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5cff4",
   "metadata": {},
   "source": [
    "## Bonus Mission\n",
    "\n",
    "Try answering the same questions for the Midwest (Chicago, Detroit, and St. Louis) or the Southeast (Atlanta, Columbia, and Miami) regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d22b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the bonus mission if you have time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
